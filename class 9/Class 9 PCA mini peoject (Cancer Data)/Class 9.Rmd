---
title: "Class 9"
author: "Tianhao Qiu"
date: "4/30/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load in Data
```{r}
# Save your input data file to a new 'data' directory
fna.data <- "WisconsinCancer.csv"

# Complete the following code to input the data and store as wisc.df
wisc.df <- read.csv(fna.data)

# Convert the other features (i.e. columns) of the data (in columns 3 through 32) to a matrix. 
wisc.data <- as.matrix(wisc.df[, 3:32])

# Set the row names of wisc.data
row.names(wisc.data) <- wisc.df$id
#$head(wisc.data)

#Store diagnosis as an independent vector 
diagnosis <- as.numeric(wisc.df$diagnosis == "M")

#Q1. How many observations are in this dataset?
nrow(wisc.data)

#Q2. How many variables/features in the data are suffixed with _mean?
length(grep("_mean", colnames(wisc.data)))

#Q3. How many of the observations have a malignant diagnosis?
table(wisc.df$diagnosis)
```

## Performing PCA
```{r}
# Check column means and standard deviations
colMeans(wisc.data)
# Look sd on column (index = 2)
round(apply(wisc.data,2,sd))

wisc.pr<- prcomp(wisc.data, scale = T)
summary(wisc.pr)

#Q4. From your results, what proportion of the original variance is captured by the first principal components (PC1)?  44%

#Q5. How many principal components (PCs) are required to describe at least 70% of the original variance in the data? 3

#Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data? 7

# Interpreting PCA
biplot(wisc.pr)
plot(wisc.pr$x[,1], wisc.pr$x[,2],  xlab = "PC1", ylab = "PC2", col = diagnosis + 1)

#Q7. What stands out to you about this plot? Is it easy or difficult to understand? Why? Useless Rubbish

#Q8. Generate a similar plot for principal components 1 and 3. What do you notice about these plots?
plot(wisc.pr$x[,c(1,3)],  xlab = "PC1", ylab = "PC3", col = diagnosis + 1)

# Overall, the plots indicate that principal component 1 is capturing a separation of malignant from benign samples. This is an important and interesting result worthy of further exploration - as we will do in the next sections!

```
##Interpreting PCA
```{r}
# Calculate the variance of each variable
pr.var <- wisc.pr$sdev^2
head(pr.var)

# Variance explained by each principal component: pve
pve <- pr.var / sum(pr.var)

# Plot variance explained for each principal component
plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")

# Alternative scree plot of the same data, note data driven y-axis
barplot(pve, ylab = "Precent of Variance Explained",
     names.arg=paste0("PC",1:length(pve)), las=2, axes = FALSE)
axis(2, at=pve, labels=round(pve,2)*100 )


par(mfrow=c(1,2))
plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
# Plot cumulative proportion of variance explained
plot(cumsum(pve), xlab = "Principal Component", 
     ylab = "Cumulative Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")

```

```{r}
#factoexrtra
library(factoextra)
fviz_eig(wisc.pr, addlabels = TRUE)
```

## Hierechical Clustering
```{r}
# Scale the wisc.data data: data.scaled
data.scaled <- scale(wisc.data)

data.dist <- dist(data.scaled)

wisc.hclust <- hclust(data.dist, method = "complete")

plot(wisc.hclust)
abline(h=19, col="red", lty=2)
wisc.hclust.clusters <- cutree(wisc.hclust, k=4)

table(wisc.hclust.clusters, diagnosis)
```

## Combining Result
```{r}
wisc.pr.hclust <- hclust(dist(wisc.pr$x[, 1:7]),  method="ward.D2")
plot(wisc.pr.hclust)

grps <- cutree(wisc.pr.hclust, k=2)
table(grps)
plot(wisc.pr$x[,1:2], col=grps)
table(grps, diagnosis)
plot(wisc.pr$x[,1:2], col=diagnosis+1)

# rgl
library(rgl)
plot3d(wisc.pr$x[,1:3], xlab="PC 1", ylab="PC 2", zlab="PC 3", cex=1.5, size=1, type="s", col=diagnosis+1)
```

## Prediction
```{r}
#url <- "new_samples.csv"
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
npc
```
```{r}
plot(wisc.pr$x[,1:2], col=grps)
points(npc[,1], npc[,2],col="blue", pch=16)
text(npc[,1], npc[,2], c(1,2), col = "white")
```

