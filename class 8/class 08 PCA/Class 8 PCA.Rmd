---
title: "Class 8"
author: "Tianhao Qiu"
date: "4/25/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## K-means
```{r}
tmp <- c(rnorm(30,-3), rnorm(30,3))
x <- cbind(x=tmp, y=rev(tmp))
plot(x)
```
```{r}

#Use the kmeans() function setting k to 2 and nstart=20
#Inspect/print the results
#Q. How many points are in each cluster? 30
#Q. What ‘component’ of your result object details
#      - cluster size? 2
#      - cluster assignment/membership?
#      - cluster center?
#Plot x colored by the kmeans cluster assignment and
#     add cluster centers as blue points
y <- kmeans(x, centers = 2, nstart = 20 )
y$size
y$center
plot(x, col = y$cluster)
points(y$centers, pch = 18, col = "blue", cex = 3 )
```

## Hierachical Clustering example
### Must give hclust() a distance matrix
```{r}
# distance matrix
d <- dist(x)

# Clustering
hc <- hclust(d)
plot(hc)

#function associated with height to determine appropriate clustering
abline(h=6, col="red")
cutree(hc, h=6)
```

### Another more complex, realistic example
```{r}
# Step 1. Generate some example data for clustering
x <- rbind(
  matrix(rnorm(100, mean=0, sd = 0.3), ncol = 2),   # c1
  matrix(rnorm(100, mean = 1, sd = 0.3), ncol = 2), # c2
  matrix(c(rnorm(50, mean = 1, sd = 0.3),           # c3
           rnorm(50, mean = 0, sd = 0.3)), ncol = 2))
colnames(x) <- c("x", "y")
# Step 2. Plot the data without clustering
plot(x)
# Step 3. Generate colors for known clusters
#         (just so we can compare to hclust results)
col <- as.factor( rep(c("c1","c2","c3"), each=50) )
plot(x, col=col)

# Q. Use the dist(), hclust(), plot() and cutree() functions to return 2 and 3 clusters
# Q. How does this compare to your known 'col' groups?
d2 <- dist(x)
hc2 <- hclust(d2)
plot(hc2)
abline(h = 2, col = "green")
abline(h = 2.6, col = "purple")
gp2 <- cutree(hc2, k = 2)
gp3 <- cutree(hc2, k = 3)
gp4 <- cutree(hc2, k = 4)
table(gp2, gp3)
plot(x, col = gp2)
plot(x, col = gp3)
plot(x, col = gp4)
```

## PCA
### We will use the  **prompt()** function for PCA
```{r}

mydata <- read.csv("https://tinyurl.com/expression-CSV",
row.names=1)
head(mydata)
```
```{r}
nrow(mydata)
ncol(mydata)
```
```{r}
# Transpose of data
t(mydata)
pca <- prcomp(t(mydata), scale = TRUE)

## See what is returned by the prcomp() function
attributes(pca)

plot(pca$x[,1], pca$x[,2])

##Calulate variance explained by each principal components
pca.var <- pca$sdev^2
pca.var.per <- round(pca.var/sum(pca.var)*100, 1)
head(pca.var.per)
```
```{r}
barplot(pca.var.per, main="Scree Plot",
  xlab="Principal Component", ylab="Percent Variation")

## A vector of colors for wt and ko samples
colvec <- colnames(mydata)
colvec[grep("wt", colvec)] <- "red"
colvec[grep("ko", colvec)] <- "blue"
plot(pca$x[,1], pca$x[,2], col=colvec, pch=16,
xlab=paste0("PC1 (", pca.var.per[1], "%)"),
ylab=paste0("PC2 (", pca.var.per[2], "%)"))
```

### UK Food Example for PCA
```{r}
# Read the data
x <- read.csv("UK_foods.csv", row.names=1)
#rownames(x) <- x[,1]
#x <- x[,-1]
nrow(x)
ncol(x)
head(x)
#tx <- t(x)
```


```{r}
barplot(as.matrix(x), beside=T, col=rainbow(nrow(x)))
barplot(as.matrix(x), beside=F, col=rainbow(nrow(x)))
```
```{r}
#Q5: Generating all pairwise plots may help somewhat. Can you make sense of the following code and resulting figure? What does it mean if a given point lies on the diagonal for a given plot?
pairs(x, col=rainbow(10), pch=16)
```
```{r}
# Now do PCA the England Dataset
pca <- prcomp( t(x) )
summary(pca)

# Plot PC1 vs PC2
plot(pca$x[,1], pca$x[,2], xlab="PC1", ylab="PC2", xlim=c(-270,500))
text(pca$x[,1], pca$x[,2], colnames(x), col = rainbow(4))

# Plot variance
v <- round( pca$sdev^2/sum(pca$sdev^2) * 100 )
barplot(v, xlab="Principal Component", ylab="Percent Variation")

## Lets focus on PC1 as it accounts for > 90% of variance 
par(mar=c(10, 3, 0.35, 0))
barplot( pca$rotation[,1], las=2 )

## The inbuilt biplot() can be useful for small datasets 
biplot(pca)
```




